name: Hulyo Scraper

on:
  schedule:
    - cron: "0 0,3,6,8,10,12,14,16,18,20,22 * * *"  # Runs on these hours UTC
  workflow_dispatch:       # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.10.8

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright
          playwright install chromium
          pip install python-dateutil

      - name: Download previous CSV artifact (if exists)
        uses: dawidd6/action-download-artifact@v2
        with:
          name: hulyo_flights
          path: .
        continue-on-error: true
    
      - name: Run scraper
        run: python -u hulyo_scraper.py

      - name: Upload debug HTML snapshot
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-before-wait
          path: page_debug_before_wait.html
          if-no-files-found: warn

      - name: Upload scraped flights CSV
        uses: actions/upload-artifact@v4
        with:
          name: hulyo_flights
          path: hulyo_flights.csv
          if-no-files-found: warn

      - name: Upload HTML snapshots
        uses: actions/upload-artifact@v4
        with:
          name: debug-html
          path: page_snapshot_*.html
          if-no-files-found: ignore

      - name: Upload HTML snapshot after clicking destination
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-after-click
          path: page_after_click.html
          if-no-files-found: warn
